# ============================================================================
# MCP Local Knowledge - Environment Variables
# ============================================================================
# Copy this file to .env in your project root or set these variables in your
# shell environment. Environment variables take precedence over config.json.
# All settings are optional - the system will use defaults if not specified.
# ============================================================================

# LanceDB Configuration
# ----------------------
# Directory where LanceDB persists vector data
# Default: ~/.knowledge-base/lancedb
LANCEDB_PERSIST_PATH=~/.knowledge-base/lancedb

# Embedding Model Configuration
# ------------------------------
# Hugging Face model name for generating embeddings
# Default: Xenova/all-MiniLM-L6-v2
# Alternative models:
#   - Xenova/all-MiniLM-L12-v2 (larger, more accurate, slower)
#   - Xenova/paraphrase-MiniLM-L6-v2 (optimized for paraphrasing)
# Note: Changing models requires re-ingesting all knowledge bases
EMBEDDING_MODEL_NAME=Xenova/all-MiniLM-L6-v2

# Directory where embedding models are cached after download
# Default: ~/.knowledge-base/models
# Models are ~100MB and downloaded once on first use
EMBEDDING_CACHE_PATH=~/.knowledge-base/models

# Fastify Server Configuration
# -----------------------------
# Port number for the Manager UI HTTP server
# Default: 8008
# Change this if port 8008 is already in use
SERVER_PORT=8008

# Host address to bind the server to
# Default: localhost
# WARNING: Do not change to 0.0.0.0 unless you understand the security implications
SERVER_HOST=localhost

# Ingestion Configuration
# -----------------------
# Number of chunks to process in each batch during ingestion
# Default: 100
# Higher values = faster ingestion but more memory usage
# Recommended range: 50-200
INGESTION_BATCH_SIZE=100

# Maximum file size in bytes to process
# Default: 1048576 (1MB)
# Files larger than this are skipped with a warning
# Example values: 524288 (512KB), 1048576 (1MB), 2097152 (2MB)
INGESTION_MAX_FILE_SIZE=1048576

# Search Configuration
# --------------------
# Default maximum number of results to return per search
# Default: 50
# Can be overridden per-query via the maxResults parameter
# Maximum allowed: 200 (enforced by the system)
SEARCH_DEFAULT_MAX_RESULTS=50

# Cache timeout in seconds for search results
# Default: 60
# Identical queries within this timeframe return cached results
# Set to 0 to disable caching (not recommended)
SEARCH_CACHE_TIMEOUT_SECONDS=60

# Document Processing Configuration
# ----------------------------------
# Timeout in milliseconds for document conversion operations
# Default: 30000 (30 seconds)
# Increase this for large or complex documents (PDFs with many pages, etc.)
# Recommended range: 10000-60000
DOCUMENT_CONVERSION_TIMEOUT=30000

# Maximum tokens per chunk when using HybridChunker
# Default: 512
# Larger values = fewer chunks but less granular search results
# Recommended range: 256-1024
DOCUMENT_MAX_TOKENS=512

# Chunk size in characters for fallback text chunking
# Default: 1000
# Used when HybridChunker is not available or fails
# Recommended range: 500-2000
DOCUMENT_CHUNK_SIZE=1000

# Overlap in characters between consecutive chunks for fallback chunking
# Default: 200
# Helps maintain context across chunk boundaries
# Recommended range: 100-400
DOCUMENT_CHUNK_OVERLAP=200

# Logging Configuration
# ---------------------
# Log level for all components
# Default: info
# Options: debug, info, warn, error
# Use "debug" for troubleshooting, "info" for normal operation
LOG_LEVEL=info

# Configuration File Path (optional)
# -----------------------------------
# Path to JSON configuration file
# If specified, settings from the file will be merged with environment variables
# Environment variables take precedence over config file settings
# CONFIG_PATH=~/.knowledge-base/config.json
